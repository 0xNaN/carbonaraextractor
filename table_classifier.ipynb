{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas\n",
    "import numpy as np\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevant</th>\n",
       "      <th>depth</th>\n",
       "      <th>number_bold</th>\n",
       "      <th>number_br</th>\n",
       "      <th>number_div</th>\n",
       "      <th>number_img</th>\n",
       "      <th>number_li</th>\n",
       "      <th>number_links</th>\n",
       "      <th>number_p</th>\n",
       "      <th>number_relevants</th>\n",
       "      <th>number_td</th>\n",
       "      <th>number_th</th>\n",
       "      <th>number_tr</th>\n",
       "      <th>relevants_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>86</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   relevant  depth  number_bold  number_br  number_div  number_img  number_li  \\\n",
       "0         0      7            0          0          14           6          0   \n",
       "1         0      3            1          0           0           0          0   \n",
       "2         0      5           15         60           0           0          0   \n",
       "3         1      3            0          0           0           0          0   \n",
       "4         1      4            7          0           0           0          0   \n",
       "\n",
       "   number_links  number_p  number_relevants  number_td  number_th  number_tr  \\\n",
       "0            20         0                80         86         19         16   \n",
       "1             0         0                 2          2          1          2   \n",
       "2             0         0               142          5          0          1   \n",
       "3             0         0                60         54          0         27   \n",
       "4             0         0                46         53         53         53   \n",
       "\n",
       "   relevants_ratio  \n",
       "0             0.48  \n",
       "1             0.33  \n",
       "2             0.42  \n",
       "3             0.65  \n",
       "4             0.30  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pandas.read_csv(\"data/table2.csv\", sep=\"\\t\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analisi features\n",
    "Addestrando una rete (epochs:5, neurons:16, batch_size:16, activation:'tanh')\n",
    "    \n",
    "con KFold(8), utilizzando **una** sola feature si Ã¨ ottenuto\n",
    "\n",
    "       1. depth                loss: 0.338, acc: 0.068 (std: 0.137)\n",
    "       2. number_links         loss: 0.293, acc: 0.437 (std: 0.350)\n",
    "       3. number_relevants     loss: 0.303, acc: 0.240 (std: 0.216)\n",
    "       4. number_td            loss: 0.289, acc: 0.440 (std: 0.262)\n",
    "       5. number_th            loss: 0.302, acc: 0.292 (std: 0.305)\n",
    "       6. number_tr            loss: 0.287, acc: 0.450 (std: 0.254)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['number_bold', 'number_img', 'number_links', 'number_relevants', 'number_td', 'number_tr', 'relevants_ratio']\n",
      "[ 0.    6.   20.   80.   86.   16.    0.48]\n"
     ]
    }
   ],
   "source": [
    "# Dataset to numpy arrays\n",
    "\n",
    "# choose the target feature and the features to train on\n",
    "TARGET_FEATURE = 'relevant'\n",
    "CHOSEN_FEATURES = ['number_img', 'number_td', 'number_tr', 'number_relevants', 'number_links', 'number_bold', 'relevants_ratio']\n",
    "#CHOSEN_FEATURES = [\"relevants_ratio\"]\n",
    "\n",
    "CHOSEN_FEATURES = sorted(CHOSEN_FEATURES) # XXX as convention we sort the features based on their names\n",
    "print(CHOSEN_FEATURES)\n",
    "\n",
    "if (TARGET_FEATURE in CHOSEN_FEATURES): CHOSEN_FEATURES.remove(TARGET_FEATURE) # ensure we do not use target feature\n",
    "\n",
    "data  = np.ndarray((len(dataset), len(CHOSEN_FEATURES)), np.float32)\n",
    "label = np.ndarray((len(dataset), 1), np.float32)\n",
    "\n",
    "for i, row in dataset.iterrows():\n",
    "    label[i] = row[TARGET_FEATURE]\n",
    "    data[i]  = np.fromiter([row[feature] for feature in CHOSEN_FEATURES], np.float32)\n",
    "    \n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "\n",
    "def table_classifier(neuron, activation, input_shape=()):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron, input_shape=input_shape, activation=activation))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", \n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(30, 8, 32, 'tanh'), (30, 8, 32, 'sigmoid')]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train & test\n",
    "import itertools\n",
    "\n",
    "loo = KFold(8)\n",
    "\n",
    "epochs = [30]\n",
    "batch_size = [8]\n",
    "neurons = [32]\n",
    "activation = ['tanh', 'sigmoid']\n",
    "\n",
    "hyperparams = list(itertools.product(epochs, batch_size, neurons, activation))\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02810156703528828, 0.9737991266375546]\n",
      "[0.03290202643917507, 0.9650655021834061]\n",
      "Epoch 00028: early stopping\n",
      "[0.06643162058934765, 0.9126637554585153]\n",
      "[0.0338356675492197, 0.9563318777292577]\n",
      "[0.048616986844296516, 0.9473684210526315]\n",
      "[0.03325533879953518, 0.9649122807017544]\n",
      "Epoch 00029: early stopping\n",
      "[0.023429387700417192, 0.9692982456140351]\n",
      "[0.04417674664364313, 0.9342105263157895]\n",
      "(30, 8, 32, tanh)  - loss: 0.03884366770011534, acc: 0.952956216961618 (std: 0.020731525178141065)\n",
      "\n",
      "[0.031986238876170595, 0.9650655021834061]\n",
      "[0.037131290933662235, 0.9563318777292577]\n",
      "[0.06455956624353643, 0.9082969432314411]\n",
      "[0.04231700355870299, 0.9388646288209607]\n",
      "[0.05650026174752336, 0.9429824561403509]\n",
      "[0.037979137871349065, 0.9605263157894737]\n",
      "[0.025795557564778023, 0.9692982456140351]\n",
      "[0.048817538245777156, 0.9385964912280702]\n",
      "(30, 8, 32, sigmoid)  - loss: 0.04313582438018748, acc: 0.9474953075921244 (std: 0.019793675527809685)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "early_stop_val_acc = EarlyStopping(monitor = \"val_loss\", min_delta=0.0005, patience=5, verbose=True)\n",
    "\n",
    "for epoch, batch, neuron, activation in hyperparams:\n",
    "\n",
    "    res = []\n",
    "    for (i, (train_index, test_index)) in enumerate(loo.split(data)):\n",
    "        \n",
    "        model = table_classifier(neuron, activation, input_shape=(len(CHOSEN_FEATURES),))\n",
    "        \n",
    "        data_train,   data_test =  data[train_index],  data[test_index]\n",
    "        label_train, label_test = label[train_index], label[test_index]\n",
    "        \n",
    "        \n",
    "        t = model.fit(data_train, label_train, epochs=epoch, batch_size=batch, shuffle=True, verbose=False,\n",
    "                 validation_split=0.3, callbacks=[early_stop_val_acc])\n",
    "        \n",
    "        r = model.evaluate(data_test, label_test, verbose=False)\n",
    "        print(r)\n",
    "        res.append(r)\n",
    "        \n",
    "    loss = statistics.mean(list(map(lambda x: x[0], res)))\n",
    "    acc  = statistics.mean(list(map(lambda x: x[1], res)))\n",
    "    acc_std = statistics.stdev(list(map(lambda x: x[1], res)))\n",
    "    \n",
    "    print(\"({}, {}, {}, {})  - loss: {}, acc: {} (std: {})\".format(epoch, batch, neuron, activation,\n",
    "                                                                   loss, acc, acc_std))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set the best hyperparameters from the results above\n",
    "best_epochs = 30    \n",
    "best_batch_size = 8\n",
    "best_neurons = 32\n",
    "best_activation = 'tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1828/1828 [==============================] - 12s 7ms/step - loss: 0.2189 - acc: 0.6854\n",
      "Epoch 2/30\n",
      "1828/1828 [==============================] - 0s 178us/step - loss: 0.1390 - acc: 0.8446\n",
      "Epoch 3/30\n",
      "1828/1828 [==============================] - 0s 167us/step - loss: 0.1070 - acc: 0.9026\n",
      "Epoch 4/30\n",
      "1828/1828 [==============================] - 0s 187us/step - loss: 0.0861 - acc: 0.9201\n",
      "Epoch 5/30\n",
      "1828/1828 [==============================] - 0s 143us/step - loss: 0.0730 - acc: 0.9294\n",
      "Epoch 6/30\n",
      "1828/1828 [==============================] - 0s 162us/step - loss: 0.0647 - acc: 0.9333\n",
      "Epoch 7/30\n",
      "1828/1828 [==============================] - 0s 185us/step - loss: 0.0594 - acc: 0.9349\n",
      "Epoch 8/30\n",
      "1828/1828 [==============================] - 0s 169us/step - loss: 0.0562 - acc: 0.9344\n",
      "Epoch 9/30\n",
      "1828/1828 [==============================] - 0s 187us/step - loss: 0.0536 - acc: 0.9371\n",
      "Epoch 10/30\n",
      "1828/1828 [==============================] - 0s 198us/step - loss: 0.0519 - acc: 0.9442\n",
      "Epoch 11/30\n",
      "1828/1828 [==============================] - 0s 178us/step - loss: 0.0503 - acc: 0.9442\n",
      "Epoch 12/30\n",
      "1828/1828 [==============================] - 0s 175us/step - loss: 0.0489 - acc: 0.9437\n",
      "Epoch 13/30\n",
      "1828/1828 [==============================] - 0s 181us/step - loss: 0.0480 - acc: 0.9447\n",
      "Epoch 14/30\n",
      "1828/1828 [==============================] - 0s 183us/step - loss: 0.0476 - acc: 0.9469\n",
      "Epoch 15/30\n",
      "1828/1828 [==============================] - 0s 177us/step - loss: 0.0467 - acc: 0.9453\n",
      "Epoch 16/30\n",
      "1828/1828 [==============================] - 0s 181us/step - loss: 0.0456 - acc: 0.9437\n",
      "Epoch 17/30\n",
      "1828/1828 [==============================] - 0s 184us/step - loss: 0.0449 - acc: 0.9497\n",
      "Epoch 18/30\n",
      "1828/1828 [==============================] - 0s 181us/step - loss: 0.0451 - acc: 0.9458\n",
      "Epoch 19/30\n",
      "1828/1828 [==============================] - 0s 224us/step - loss: 0.0440 - acc: 0.9497\n",
      "Epoch 20/30\n",
      "1828/1828 [==============================] - 0s 210us/step - loss: 0.0434 - acc: 0.9464\n",
      "Epoch 21/30\n",
      "1828/1828 [==============================] - 0s 208us/step - loss: 0.0430 - acc: 0.9497\n",
      "Epoch 22/30\n",
      "1828/1828 [==============================] - 0s 224us/step - loss: 0.0424 - acc: 0.9469\n",
      "Epoch 23/30\n",
      "1828/1828 [==============================] - 0s 238us/step - loss: 0.0422 - acc: 0.9502\n",
      "Epoch 24/30\n",
      "1828/1828 [==============================] - 0s 234us/step - loss: 0.0420 - acc: 0.9464\n",
      "Epoch 25/30\n",
      "1828/1828 [==============================] - 0s 267us/step - loss: 0.0419 - acc: 0.9486\n",
      "Epoch 26/30\n",
      "1828/1828 [==============================] - 0s 228us/step - loss: 0.0409 - acc: 0.9502\n",
      "Epoch 27/30\n",
      "1828/1828 [==============================] - 0s 241us/step - loss: 0.0406 - acc: 0.9497\n",
      "Epoch 28/30\n",
      "1828/1828 [==============================] - 0s 209us/step - loss: 0.0402 - acc: 0.9508\n",
      "Epoch 29/30\n",
      "1828/1828 [==============================] - 0s 213us/step - loss: 0.0403 - acc: 0.9480\n",
      "Epoch 30/30\n",
      "1828/1828 [==============================] - 0s 239us/step - loss: 0.0396 - acc: 0.9508\n"
     ]
    }
   ],
   "source": [
    "## retrain the model on the whole dataset and save it\n",
    "model = table_classifier(best_neurons, best_activation, input_shape=(len(CHOSEN_FEATURES),))\n",
    "\n",
    "model.fit(data, label, epochs=best_epochs, \n",
    "                       batch_size=best_epochs, \n",
    "                       shuffle=True, verbose=True)\n",
    "\n",
    "model.save(\"models/table_classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
