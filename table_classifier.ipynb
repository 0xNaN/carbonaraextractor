{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas\n",
    "import numpy as np\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevant</th>\n",
       "      <th>depth</th>\n",
       "      <th>number_bold</th>\n",
       "      <th>number_br</th>\n",
       "      <th>number_div</th>\n",
       "      <th>number_img</th>\n",
       "      <th>number_li</th>\n",
       "      <th>number_links</th>\n",
       "      <th>number_p</th>\n",
       "      <th>number_relevants</th>\n",
       "      <th>number_td</th>\n",
       "      <th>number_th</th>\n",
       "      <th>number_tr</th>\n",
       "      <th>relevants_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   relevant  depth  number_bold  number_br  number_div  number_img  number_li  \\\n",
       "0         1      6            3          0           2           0          0   \n",
       "1         0      3           10          0           0           0          0   \n",
       "2         0     14            1          1           5           5          0   \n",
       "3         1      6            3          0           2           0          0   \n",
       "4         0      3           14          0           0           0          0   \n",
       "\n",
       "   number_links  number_p  number_relevants  number_td  number_th  number_tr  \\\n",
       "0             1         0                55          2          2          2   \n",
       "1             0         0                15         20          1         11   \n",
       "2             0         0                16          7          0          5   \n",
       "3             1         0                32          2          2          2   \n",
       "4             0         0                16         28          1         15   \n",
       "\n",
       "   relevants_ratio  \n",
       "0             0.50  \n",
       "1             0.28  \n",
       "2             0.39  \n",
       "3             0.53  \n",
       "4             0.13  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pandas.read_csv(\"data/table2.csv\", sep=\"\\t\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analisi features\n",
    "Addestrando una rete (epochs:5, neurons:16, batch_size:16, activation:'tanh')\n",
    "    \n",
    "con KFold(8), utilizzando **una** sola feature si Ã¨ ottenuto\n",
    "\n",
    "       1. depth                loss: 0.338, acc: 0.068 (std: 0.137)\n",
    "       2. number_links         loss: 0.293, acc: 0.437 (std: 0.350)\n",
    "       3. number_relevants     loss: 0.303, acc: 0.240 (std: 0.216)\n",
    "       4. number_td            loss: 0.289, acc: 0.440 (std: 0.262)\n",
    "       5. number_th            loss: 0.302, acc: 0.292 (std: 0.305)\n",
    "       6. number_tr            loss: 0.287, acc: 0.450 (std: 0.254)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['number_bold', 'number_img', 'number_links', 'number_relevants', 'number_td', 'number_tr', 'relevants_ratio']\n",
      "[ 3.   0.   1.  55.   2.   2.   0.5]\n"
     ]
    }
   ],
   "source": [
    "# Dataset to numpy arrays\n",
    "\n",
    "# choose the target feature and the features to train on\n",
    "TARGET_FEATURE = 'relevant'\n",
    "CHOSEN_FEATURES = ['number_img', 'number_td', 'number_tr', 'number_relevants', 'number_links', 'number_bold', 'relevants_ratio']\n",
    "\n",
    "CHOSEN_FEATURES = sorted(CHOSEN_FEATURES) # XXX as convention we sort the features based on their names\n",
    "print(CHOSEN_FEATURES)\n",
    "\n",
    "if (TARGET_FEATURE in CHOSEN_FEATURES): CHOSEN_FEATURES.remove(TARGET_FEATURE) # ensure we do not use target feature\n",
    "\n",
    "data  = np.ndarray((len(dataset), len(CHOSEN_FEATURES)), np.float32)\n",
    "label = np.ndarray((len(dataset), 1), np.float32)\n",
    "\n",
    "for i, row in dataset.iterrows():\n",
    "    label[i] = row[TARGET_FEATURE]\n",
    "    data[i]  = np.fromiter([row[feature] for feature in CHOSEN_FEATURES], np.float32)\n",
    "    \n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "\n",
    "def table_classifier(neuron, activation, input_shape=()):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron, input_shape=input_shape, activation=activation))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", \n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(30, 8, 32, 'tanh'), (30, 8, 32, 'sigmoid')]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train & test\n",
    "import itertools\n",
    "\n",
    "loo = KFold(8)\n",
    "\n",
    "epochs = [30]\n",
    "batch_size = [8]\n",
    "neurons = [32]\n",
    "activation = ['tanh', 'sigmoid']\n",
    "\n",
    "hyperparams = list(itertools.product(epochs, batch_size, neurons, activation))\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.040347829328051636, 0.9464285714285714]\n",
      "[0.045884401884113725, 0.9282511213435186]\n",
      "Epoch 00021: early stopping\n",
      "[0.05437118991073472, 0.9327354265435395]\n",
      "[0.03965112994604581, 0.9461883410744603]\n",
      "[0.033167422786689126, 0.968609865470852]\n",
      "Epoch 00019: early stopping\n",
      "[0.06526916210159593, 0.9192825077360521]\n",
      "Epoch 00023: early stopping\n",
      "[0.07467027098742302, 0.8968609828050895]\n",
      "Epoch 00024: early stopping\n",
      "[0.07291455358066366, 0.901345287737825]\n",
      "(30, 8, 32, tanh)  - loss: 0.053284495065664704, acc: 0.9299627630174886 (std: 0.024105019440806705)\n",
      "\n",
      "Epoch 00021: early stopping\n",
      "[0.04702323914638588, 0.9330357142857143]\n",
      "Epoch 00020: early stopping\n",
      "[0.061608531199094964, 0.905829592403275]\n",
      "Epoch 00026: early stopping\n",
      "[0.058574520118300694, 0.9058295929378458]\n",
      "[0.050153423986092814, 0.9147982028033167]\n",
      "[0.04481445311364037, 0.9417040361417248]\n",
      "Epoch 00022: early stopping\n",
      "[0.07069648347895241, 0.9013452880051104]\n",
      "[0.0731907311509543, 0.8923766818816352]\n",
      "Epoch 00027: early stopping\n",
      "[0.07635830762073598, 0.8878923769488998]\n",
      "(30, 8, 32, sigmoid)  - loss: 0.060302461226769674, acc: 0.9103514356759402 (std: 0.018772478742517956)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "early_stop_val_acc = EarlyStopping(monitor = \"val_loss\", min_delta=0.0005, patience=5, verbose=True)\n",
    "\n",
    "for epoch, batch, neuron, activation in hyperparams:\n",
    "\n",
    "    res = []\n",
    "    for (i, (train_index, test_index)) in enumerate(loo.split(data)):\n",
    "        \n",
    "        model = table_classifier(neuron, activation, input_shape=(len(CHOSEN_FEATURES),))\n",
    "        \n",
    "        data_train,   data_test =  data[train_index],  data[test_index]\n",
    "        label_train, label_test = label[train_index], label[test_index]\n",
    "        \n",
    "        \n",
    "        t = model.fit(data_train, label_train, epochs=epoch, batch_size=batch, shuffle=True, verbose=False,\n",
    "                 validation_split=0.3, callbacks=[early_stop_val_acc])\n",
    "        \n",
    "        r = model.evaluate(data_test, label_test, verbose=False)\n",
    "        print(r)\n",
    "        res.append(r)\n",
    "        \n",
    "    loss = statistics.mean(list(map(lambda x: x[0], res)))\n",
    "    acc  = statistics.mean(list(map(lambda x: x[1], res)))\n",
    "    acc_std = statistics.stdev(list(map(lambda x: x[1], res)))\n",
    "    \n",
    "    print(\"({}, {}, {}, {})  - loss: {}, acc: {} (std: {})\".format(epoch, batch, neuron, activation,\n",
    "                                                                   loss, acc, acc_std))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set the best hyperparameters from the results above\n",
    "best_epochs = 30    \n",
    "best_batch_size = 8\n",
    "best_neurons = 32\n",
    "best_activation = 'tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1785/1785 [==============================] - 12s 7ms/step - loss: 0.2441 - acc: 0.6034\n",
      "Epoch 2/30\n",
      "1785/1785 [==============================] - 0s 220us/step - loss: 0.1685 - acc: 0.7574\n",
      "Epoch 3/30\n",
      "1785/1785 [==============================] - 0s 178us/step - loss: 0.1376 - acc: 0.8415\n",
      "Epoch 4/30\n",
      "1785/1785 [==============================] - 0s 171us/step - loss: 0.1135 - acc: 0.8857\n",
      "Epoch 5/30\n",
      "1785/1785 [==============================] - 0s 159us/step - loss: 0.0978 - acc: 0.8919\n",
      "Epoch 6/30\n",
      "1785/1785 [==============================] - 0s 198us/step - loss: 0.0882 - acc: 0.8941\n",
      "Epoch 7/30\n",
      "1785/1785 [==============================] - 0s 219us/step - loss: 0.0812 - acc: 0.9059\n",
      "Epoch 8/30\n",
      "1785/1785 [==============================] - 0s 171us/step - loss: 0.0737 - acc: 0.9148\n",
      "Epoch 9/30\n",
      "1785/1785 [==============================] - 0s 190us/step - loss: 0.0699 - acc: 0.9227\n",
      "Epoch 10/30\n",
      "1785/1785 [==============================] - 0s 185us/step - loss: 0.0673 - acc: 0.9160\n",
      "Epoch 11/30\n",
      "1785/1785 [==============================] - 0s 155us/step - loss: 0.0647 - acc: 0.9232\n",
      "Epoch 12/30\n",
      "1785/1785 [==============================] - 0s 170us/step - loss: 0.0624 - acc: 0.9289\n",
      "Epoch 13/30\n",
      "1785/1785 [==============================] - 0s 174us/step - loss: 0.0609 - acc: 0.9305\n",
      "Epoch 14/30\n",
      "1785/1785 [==============================] - 0s 166us/step - loss: 0.0593 - acc: 0.9345\n",
      "Epoch 15/30\n",
      "1785/1785 [==============================] - 0s 151us/step - loss: 0.0581 - acc: 0.9317\n",
      "Epoch 16/30\n",
      "1785/1785 [==============================] - 0s 161us/step - loss: 0.0570 - acc: 0.9361\n",
      "Epoch 17/30\n",
      "1785/1785 [==============================] - 0s 178us/step - loss: 0.0563 - acc: 0.9322\n",
      "Epoch 18/30\n",
      "1785/1785 [==============================] - 0s 151us/step - loss: 0.0555 - acc: 0.9350\n",
      "Epoch 19/30\n",
      "1785/1785 [==============================] - 0s 181us/step - loss: 0.0550 - acc: 0.9339\n",
      "Epoch 20/30\n",
      "1785/1785 [==============================] - 0s 181us/step - loss: 0.0539 - acc: 0.9378\n",
      "Epoch 21/30\n",
      "1785/1785 [==============================] - 0s 162us/step - loss: 0.0531 - acc: 0.9412\n",
      "Epoch 22/30\n",
      "1785/1785 [==============================] - 0s 180us/step - loss: 0.0525 - acc: 0.9406\n",
      "Epoch 23/30\n",
      "1785/1785 [==============================] - 0s 205us/step - loss: 0.0516 - acc: 0.9378\n",
      "Epoch 24/30\n",
      "1785/1785 [==============================] - 0s 174us/step - loss: 0.0517 - acc: 0.9401\n",
      "Epoch 25/30\n",
      "1785/1785 [==============================] - 0s 162us/step - loss: 0.0509 - acc: 0.9445\n",
      "Epoch 26/30\n",
      "1785/1785 [==============================] - 0s 174us/step - loss: 0.0506 - acc: 0.9389\n",
      "Epoch 27/30\n",
      "1785/1785 [==============================] - 0s 166us/step - loss: 0.0503 - acc: 0.9429\n",
      "Epoch 28/30\n",
      "1785/1785 [==============================] - 0s 154us/step - loss: 0.0498 - acc: 0.9440\n",
      "Epoch 29/30\n",
      "1785/1785 [==============================] - 0s 145us/step - loss: 0.0497 - acc: 0.9445\n",
      "Epoch 30/30\n",
      "1785/1785 [==============================] - 0s 157us/step - loss: 0.0497 - acc: 0.9445\n"
     ]
    }
   ],
   "source": [
    "## retrain the model on the whole dataset and save it\n",
    "model = table_classifier(best_neurons, best_activation, input_shape=(len(CHOSEN_FEATURES),))\n",
    "\n",
    "model.fit(data, label, epochs=best_epochs, \n",
    "                       batch_size=best_epochs, \n",
    "                       shuffle=True, verbose=True)\n",
    "\n",
    "model.save(\"models/table_classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
