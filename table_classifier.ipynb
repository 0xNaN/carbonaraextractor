{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas\n",
    "import numpy as np\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevant</th>\n",
       "      <th>depth</th>\n",
       "      <th>number_bold</th>\n",
       "      <th>number_br</th>\n",
       "      <th>number_div</th>\n",
       "      <th>number_img</th>\n",
       "      <th>number_li</th>\n",
       "      <th>number_links</th>\n",
       "      <th>number_p</th>\n",
       "      <th>number_relevants</th>\n",
       "      <th>number_td</th>\n",
       "      <th>number_th</th>\n",
       "      <th>number_tr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>152</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   relevant  depth  number_bold  number_br  number_div  number_img  number_li  \\\n",
       "0         1     10            0          4           1           0          0   \n",
       "1         0      6            0          0          13           6          0   \n",
       "2         0      7            1          0           0           1          0   \n",
       "3         0      5            0          0           8           4          0   \n",
       "4         1      6            3          0           2           0          0   \n",
       "\n",
       "   number_links  number_p  number_relevants  number_td  number_th  number_tr  \n",
       "0             7         0                45          9          9          9  \n",
       "1            18         0               108        152         30         27  \n",
       "2             0         0                 1          2          0          2  \n",
       "3             0         8                43          4          4          2  \n",
       "4             1         0                48          2          2          2  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pandas.read_csv(\"data/table2.csv\", sep=\"\\t\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analisi features\n",
    "Addestrando una rete (epochs:5, neurons:16, batch_size:16, activation:'tanh')\n",
    "    \n",
    "con KFold(8), utilizzando **una** sola feature si Ã¨ ottenuto\n",
    "\n",
    "       1. depth                loss: 0.338, acc: 0.068 (std: 0.137)\n",
    "       2. number_links         loss: 0.293, acc: 0.437 (std: 0.350)\n",
    "       3. number_relevants     loss: 0.303, acc: 0.240 (std: 0.216)\n",
    "       4. number_td            loss: 0.289, acc: 0.440 (std: 0.262)\n",
    "       5. number_th            loss: 0.302, acc: 0.292 (std: 0.305)\n",
    "       6. number_tr            loss: 0.287, acc: 0.450 (std: 0.254)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['number_bold', 'number_img', 'number_links', 'number_relevants', 'number_td', 'number_tr']\n",
      "[ 0  0  7 45  9  9]\n"
     ]
    }
   ],
   "source": [
    "# Dataset to numpy arrays\n",
    "\n",
    "# choose the target feature and the features to train on\n",
    "TARGET_FEATURE = 'relevant'\n",
    "CHOSEN_FEATURES = ['number_img', 'number_td', 'number_tr', 'number_relevants', 'number_links', 'number_bold']\n",
    "\n",
    "CHOSEN_FEATURES = sorted(CHOSEN_FEATURES) # XXX as convention we sort the features based on their names\n",
    "print(CHOSEN_FEATURES)\n",
    "\n",
    "if (TARGET_FEATURE in CHOSEN_FEATURES): CHOSEN_FEATURES.remove(TARGET_FEATURE) # ensure we do not use target feature\n",
    "\n",
    "data  = np.ndarray((len(dataset), len(CHOSEN_FEATURES)), np.int)\n",
    "label = np.ndarray((len(dataset), 1), np.int)\n",
    "\n",
    "for i, row in dataset.iterrows():\n",
    "    label[i] = row[TARGET_FEATURE]\n",
    "    data[i]  = np.fromiter([row[feature] for feature in CHOSEN_FEATURES], np.int)\n",
    "    \n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "\n",
    "def table_classifier(neuron, activation, input_shape=()):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron, input_shape=input_shape, activation=activation))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop', \n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(30, 8, 16, 'tanh'),\n",
       " (30, 8, 16, 'sigmoid'),\n",
       " (30, 8, 32, 'tanh'),\n",
       " (30, 8, 32, 'sigmoid'),\n",
       " (30, 16, 16, 'tanh'),\n",
       " (30, 16, 16, 'sigmoid'),\n",
       " (30, 16, 32, 'tanh'),\n",
       " (30, 16, 32, 'sigmoid'),\n",
       " (30, 32, 16, 'tanh'),\n",
       " (30, 32, 16, 'sigmoid'),\n",
       " (30, 32, 32, 'tanh'),\n",
       " (30, 32, 32, 'sigmoid')]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train & test\n",
    "import itertools\n",
    "\n",
    "\n",
    "loo = KFold(8)\n",
    "\n",
    "epochs = [30]\n",
    "batch_size = [8, 16, 32]\n",
    "neurons = [16, 32]\n",
    "activation = ['tanh', 'sigmoid']\n",
    "\n",
    "hyperparams = list(itertools.product(epochs, batch_size, neurons, activation))\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00026: early stopping\n",
      "[0.058541366527246876, 0.9209302347759868]\n",
      "[0.09062465134748193, 0.8790697696597077]\n",
      "Epoch 00023: early stopping\n",
      "[0.07324220472297004, 0.9116279091945915]\n",
      "Epoch 00028: early stopping\n",
      "[0.05457261478485063, 0.9162790719852891]\n",
      "Epoch 00022: early stopping\n",
      "[0.0573044523250225, 0.9395348859387774]\n",
      "[0.05766247421781594, 0.9299065448413385]\n",
      "[0.04022436021505115, 0.9626168207587483]\n",
      "Epoch 00020: early stopping\n",
      "[0.07889702620211049, 0.8831775728787217]\n",
      "(30, 8, 16, tanh)  - loss: 0.06388364379281869, acc: 0.9178928512541451 (std: 0.027713848125633798)\n",
      "\n",
      "[0.06581321376007657, 0.8930232527644135]\n",
      "[0.07820115276547365, 0.8930232527644135]\n",
      "[0.08962553718755412, 0.8744186049283937]\n",
      "[0.06856921765693398, 0.9069767422454301]\n",
      "Epoch 00028: early stopping\n",
      "[0.07086370670518209, 0.9162790697674419]\n",
      "[0.07098529954379965, 0.9158878532525535]\n",
      "Epoch 00029: early stopping\n",
      "[0.055776376694997895, 0.9345794375811782]\n",
      "Epoch 00029: early stopping\n",
      "[0.05267029332223339, 0.9299065403849165]\n",
      "(30, 8, 16, sigmoid)  - loss: 0.06906309970453142, acc: 0.9080118442110926 (std: 0.020334650875284313)\n",
      "\n",
      "Epoch 00016: early stopping\n",
      "[0.05878210639537767, 0.9162790708763655]\n",
      "Epoch 00021: early stopping\n",
      "[0.052210608159386836, 0.9209302347759868]\n",
      "Epoch 00016: early stopping\n",
      "[0.07738431979750478, 0.8883720910826395]\n",
      "Epoch 00022: early stopping\n",
      "[0.05146423179742902, 0.9348837220391562]\n",
      "Epoch 00020: early stopping\n",
      "[0.05352932178350382, 0.9255813964577608]\n",
      "Epoch 00020: early stopping\n",
      "[0.04342933086173557, 0.9579439252336449]\n",
      "Epoch 00022: early stopping\n",
      "[0.045457016885559136, 0.9439252364301236]\n",
      "Epoch 00017: early stopping\n",
      "[0.05097030399140911, 0.9252336431886549]\n",
      "(30, 8, 32, tanh)  - loss: 0.05415340495898824, acc: 0.9266436650105415 (std: 0.020543179556887142)\n",
      "\n",
      "Epoch 00019: early stopping\n",
      "[0.06567257802153742, 0.9116279039272043]\n",
      "Epoch 00025: early stopping\n",
      "[0.06463093282871468, 0.8976744155551112]\n",
      "Epoch 00022: early stopping\n",
      "[0.08767478154149166, 0.8511627909749053]\n",
      "Epoch 00030: early stopping\n",
      "[0.05415227444365967, 0.9209302347759868]\n",
      "Epoch 00020: early stopping\n",
      "[0.06912185932661212, 0.9023255825042724]\n",
      "Epoch 00028: early stopping\n",
      "[0.05682240635435158, 0.9065420571888718]\n",
      "Epoch 00021: early stopping\n",
      "[0.05259487663056249, 0.9205607459923931]\n",
      "Epoch 00024: early stopping\n",
      "[0.05183376662572411, 0.9112149515998698]\n",
      "(30, 8, 32, sigmoid)  - loss: 0.06281293447158172, acc: 0.9027548353148268 (std: 0.02235996909783374)\n",
      "\n",
      "[0.07006753849428754, 0.9255813975666844]\n",
      "[0.1104232247485671, 0.809302323640779]\n",
      "Epoch 00025: early stopping\n",
      "[0.07572295540987059, 0.8744186016016229]\n",
      "Epoch 00028: early stopping\n",
      "[0.06494268120028251, 0.9395348837209302]\n",
      "[0.06866528166587962, 0.9162790708763655]\n",
      "[0.06030926957865742, 0.9065420555177136]\n",
      "[0.08592025817276161, 0.8971962600110848]\n",
      "Epoch 00028: early stopping\n",
      "[0.05383282095611652, 0.9392523364485982]\n",
      "(30, 16, 16, tanh)  - loss: 0.07373550377830286, acc: 0.9010133661729723 (std: 0.04300513191778145)\n",
      "\n",
      "Epoch 00030: early stopping\n",
      "[0.07235262012758921, 0.9116279039272043]\n",
      "[0.10777745156787162, 0.9116279039272043]\n",
      "[0.11329577211723771, 0.8651162793469983]\n",
      "[0.06292391239210617, 0.9209302306175232]\n",
      "[0.08185843683259432, 0.9162790697674419]\n",
      "[0.08123995064296455, 0.9065420555177136]\n",
      "[0.060393574221111905, 0.9252336431886549]\n",
      "[0.06611888761693072, 0.9158878487961315]\n",
      "(30, 16, 16, sigmoid)  - loss: 0.08074507568980077, acc: 0.909155616886109 (std: 0.01871488844319825)\n",
      "\n",
      "Epoch 00026: early stopping\n",
      "[0.054381775873345, 0.9209302347759868]\n",
      "Epoch 00021: early stopping\n",
      "[0.05928685561169025, 0.9255813922992973]\n",
      "Epoch 00028: early stopping\n",
      "[0.06763166653555493, 0.9023255783458088]\n",
      "[0.04880321989225787, 0.9488372093023256]\n",
      "Epoch 00024: early stopping\n",
      "[0.05840420017755309, 0.9162790708763655]\n",
      "Epoch 00023: early stopping\n",
      "[0.047712959349155426, 0.9392523375627037]\n",
      "Epoch 00024: early stopping\n",
      "[0.045702091966555496, 0.9299065403849165]\n",
      "Epoch 00020: early stopping\n",
      "[0.05249054101513368, 0.9299065420560748]\n",
      "(30, 16, 32, tanh)  - loss: 0.05430166380265572, acc: 0.9266273632004349 (std: 0.014169325455502821)\n",
      "\n",
      "Epoch 00030: early stopping\n",
      "[0.06439201741717583, 0.8976744155551112]\n",
      "[0.06768898759470429, 0.9069767411365065]\n",
      "Epoch 00024: early stopping\n",
      "[0.09502810898215272, 0.855813953765603]\n",
      "Epoch 00027: early stopping\n",
      "[0.06231246971806814, 0.9209302306175232]\n",
      "Epoch 00028: early stopping\n",
      "[0.068311037192511, 0.9116279080856678]\n",
      "Epoch 00029: early stopping\n",
      "[0.05751660292115167, 0.9065420571888718]\n",
      "Epoch 00028: early stopping\n",
      "[0.05381329932084707, 0.9299065420560748]\n",
      "Epoch 00029: early stopping\n",
      "[0.05558608106781389, 0.9065420544036081]\n",
      "(30, 16, 32, sigmoid)  - loss: 0.06558107552680308, acc: 0.9045017378511209 (std: 0.022031295397580447)\n",
      "\n",
      "[0.07313093380179517, 0.9116279039272043]\n",
      "[0.07968599865602892, 0.8930232527644135]\n",
      "[0.10838541135538456, 0.8651162771291511]\n",
      "[0.07008912092031434, 0.9209302306175232]\n",
      "[0.07788406643410062, 0.9023255825042724]\n",
      "[0.06995531060149736, 0.9018691583214519]\n",
      "[0.06672757289537759, 0.9345794375811782]\n",
      "[0.0919170995181966, 0.8691588785046729]\n",
      "(30, 32, 16, tanh)  - loss: 0.0797219392728369, acc: 0.8998288401687334 (std: 0.023887868488881542)\n",
      "\n",
      "[0.08998464872670728, 0.8651162771291511]\n",
      "[0.09748142801744994, 0.9069767411365065]\n",
      "[0.10535978217457616, 0.8604651165563006]\n",
      "[0.09800818326861359, 0.8604651187741479]\n",
      "[0.090144405981829, 0.9069767452949702]\n",
      "[0.09094129398325894, 0.8785046723401435]\n",
      "[0.09080883609914334, 0.9392523347774399]\n",
      "[0.08968266949196842, 0.9065420588600301]\n",
      "(30, 32, 16, sigmoid)  - loss: 0.09405140596794333, acc: 0.8905373831085862 (std: 0.028709138263724565)\n",
      "\n",
      "[0.060533213164917256, 0.9302325603573821]\n",
      "Epoch 00027: early stopping\n",
      "[0.05785442050113234, 0.9255813922992973]\n",
      "[0.07237732469342475, 0.9162790667179019]\n",
      "Epoch 00024: early stopping\n",
      "[0.0497322169500728, 0.9255813934082209]\n",
      "[0.0599517019508883, 0.9348837231480798]\n",
      "Epoch 00025: early stopping\n",
      "[0.05489779396034847, 0.9205607504488151]\n",
      "Epoch 00027: early stopping\n",
      "[0.047457833783091784, 0.9252336431886549]\n",
      "Epoch 00027: early stopping\n",
      "[0.05004922638290396, 0.9299065403849165]\n",
      "(30, 32, 32, tanh)  - loss: 0.056606716423347456, acc: 0.9260323837441585 (std: 0.005820008817833757)\n",
      "\n",
      "[0.07866752324409262, 0.9069767411365065]\n",
      "[0.08134963772324628, 0.9069767411365065]\n",
      "Epoch 00028: early stopping\n",
      "[0.09867159010365951, 0.869767442137696]\n",
      "[0.0738629290530848, 0.9116279039272043]\n",
      "[0.07439670453584471, 0.9023255825042724]\n",
      "[0.0730846703191784, 0.9018691599926102]\n",
      "[0.06970834467455606, 0.9252336431886549]\n",
      "Epoch 00026: early stopping\n",
      "[0.06356876402675549, 0.9112149515998698]\n",
      "(30, 32, 32, sigmoid)  - loss: 0.07666377046005224, acc: 0.9044990207029151 (std: 0.015838695929135765)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "early_stop_val_acc = EarlyStopping(monitor = \"val_loss\", min_delta=0.005, patience=5, verbose=True)\n",
    "\n",
    "for epoch, batch, neuron, activation in hyperparams:\n",
    "\n",
    "    res = []\n",
    "    for (i, (train_index, test_index)) in enumerate(loo.split(data)):\n",
    "        \n",
    "        model = table_classifier(neuron, activation, input_shape=(len(CHOSEN_FEATURES),))\n",
    "        \n",
    "        data_train,   data_test =  data[train_index],  data[test_index]\n",
    "        label_train, label_test = label[train_index], label[test_index]\n",
    "        \n",
    "        \n",
    "        model.fit(data_train, label_train, epochs=epoch, batch_size=batch, shuffle=True, verbose=False,\n",
    "                 validation_split=0.3, callbacks=[early_stop_val_acc])\n",
    "        \n",
    "        r = model.evaluate(data_test, label_test, verbose=False)\n",
    "        print(r)\n",
    "        res.append(r)\n",
    "        \n",
    "    loss = statistics.mean(list(map(lambda x: x[0], res)))\n",
    "    acc  = statistics.mean(list(map(lambda x: x[1], res)))\n",
    "    acc_std = statistics.stdev(list(map(lambda x: x[1], res)))\n",
    "    \n",
    "    print(\"({}, {}, {}, {})  - loss: {}, acc: {} (std: {})\".format(epoch, batch, neuron, activation,\n",
    "                                                                   loss, acc, acc_std))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set the best hyperparameters from the results above\n",
    "best_epochs = 20    \n",
    "best_batch_size = 8\n",
    "best_neurons = 32\n",
    "best_activation = 'tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1717/1717 [==============================] - 9s 5ms/step - loss: 0.1932 - acc: 0.7513\n",
      "Epoch 2/20\n",
      "1717/1717 [==============================] - 0s 209us/step - loss: 0.1485 - acc: 0.8451\n",
      "Epoch 3/20\n",
      "1717/1717 [==============================] - 0s 205us/step - loss: 0.1266 - acc: 0.8573\n",
      "Epoch 4/20\n",
      "1717/1717 [==============================] - 0s 215us/step - loss: 0.1092 - acc: 0.8655\n",
      "Epoch 5/20\n",
      "1717/1717 [==============================] - 0s 208us/step - loss: 0.0949 - acc: 0.8672\n",
      "Epoch 6/20\n",
      "1717/1717 [==============================] - 0s 199us/step - loss: 0.0851 - acc: 0.8952\n",
      "Epoch 7/20\n",
      "1717/1717 [==============================] - 0s 212us/step - loss: 0.0775 - acc: 0.9080\n",
      "Epoch 8/20\n",
      "1717/1717 [==============================] - 0s 201us/step - loss: 0.0720 - acc: 0.9086\n",
      "Epoch 9/20\n",
      "1717/1717 [==============================] - 0s 202us/step - loss: 0.0673 - acc: 0.9121\n",
      "Epoch 10/20\n",
      "1717/1717 [==============================] - 0s 203us/step - loss: 0.0639 - acc: 0.9132\n",
      "Epoch 11/20\n",
      "1717/1717 [==============================] - 0s 204us/step - loss: 0.0608 - acc: 0.9196\n",
      "Epoch 12/20\n",
      "1717/1717 [==============================] - 0s 200us/step - loss: 0.0583 - acc: 0.9156\n",
      "Epoch 13/20\n",
      "1717/1717 [==============================] - 0s 205us/step - loss: 0.0558 - acc: 0.9196\n",
      "Epoch 14/20\n",
      "1717/1717 [==============================] - 0s 213us/step - loss: 0.0543 - acc: 0.9220\n",
      "Epoch 15/20\n",
      "1717/1717 [==============================] - 0s 201us/step - loss: 0.0524 - acc: 0.9313\n",
      "Epoch 16/20\n",
      "1717/1717 [==============================] - 0s 205us/step - loss: 0.0513 - acc: 0.9295\n",
      "Epoch 17/20\n",
      "1717/1717 [==============================] - 0s 193us/step - loss: 0.0501 - acc: 0.9324\n",
      "Epoch 18/20\n",
      "1717/1717 [==============================] - 0s 197us/step - loss: 0.0493 - acc: 0.9307\n",
      "Epoch 19/20\n",
      "1717/1717 [==============================] - 0s 193us/step - loss: 0.0476 - acc: 0.9371\n",
      "Epoch 20/20\n",
      "1717/1717 [==============================] - 0s 203us/step - loss: 0.0470 - acc: 0.9394\n"
     ]
    }
   ],
   "source": [
    "## retrain the model on the whole dataset and save it\n",
    "model = table_classifier(best_neurons, best_activation, input_shape=(len(CHOSEN_FEATURES),))\n",
    "\n",
    "model.fit(data, label, epochs=best_epochs, \n",
    "                       batch_size=best_epochs, \n",
    "                       shuffle=True, verbose=True)\n",
    "\n",
    "model.save(\"models/table_classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
