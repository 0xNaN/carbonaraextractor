{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas\n",
    "import numpy as np\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevant</th>\n",
       "      <th>avg_tag_in_li</th>\n",
       "      <th>depth</th>\n",
       "      <th>number_bold</th>\n",
       "      <th>number_br</th>\n",
       "      <th>number_div</th>\n",
       "      <th>number_img</th>\n",
       "      <th>number_links</th>\n",
       "      <th>number_p</th>\n",
       "      <th>number_relevants</th>\n",
       "      <th>number_row</th>\n",
       "      <th>relevants_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.38</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   relevant  avg_tag_in_li  depth  number_bold  number_br  number_div  \\\n",
       "0         1           0.00      2            2         26           0   \n",
       "1         1           0.00      1            0          0           0   \n",
       "2         1           1.00      2            0          0           0   \n",
       "3         1           1.38      5            0          0           4   \n",
       "4         1           2.50      5            0          0           4   \n",
       "\n",
       "   number_img  number_links  number_p  number_relevants  number_row  \\\n",
       "0           0             0         0                28           1   \n",
       "1           0             0         0                20           5   \n",
       "2           0             0         0                29           6   \n",
       "3           0             1         0                35           8   \n",
       "4           0             1         0                19           2   \n",
       "\n",
       "   relevants_ratio  \n",
       "0             0.12  \n",
       "1             0.51  \n",
       "2             0.52  \n",
       "3             0.48  \n",
       "4             0.59  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pandas.read_csv(\"data/list.csv\", sep=\"\\t\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['avg_tag_in_li', 'number_bold', 'number_img', 'number_links', 'number_relevants', 'relevants_ratio']\n",
      "[ 0.    2.    0.    0.   28.    0.12]\n"
     ]
    }
   ],
   "source": [
    "# Dataset to numpy arrays\n",
    "\n",
    "# choose the target feature and the features to train on\n",
    "TARGET_FEATURE = 'relevant'\n",
    "CHOSEN_FEATURES = ['avg_tag_in_li', 'number_img', 'number_relevants', 'number_links', 'number_bold', 'relevants_ratio']\n",
    "#CHOSEN_FEATURES = [\"relevants_ratio\"]\n",
    "\n",
    "CHOSEN_FEATURES = sorted(CHOSEN_FEATURES) # XXX as convention we sort the features based on their names\n",
    "print(CHOSEN_FEATURES)\n",
    "\n",
    "if (TARGET_FEATURE in CHOSEN_FEATURES): CHOSEN_FEATURES.remove(TARGET_FEATURE) # ensure we do not use target feature\n",
    "\n",
    "data  = np.ndarray((len(dataset), len(CHOSEN_FEATURES)), np.float32)\n",
    "label = np.ndarray((len(dataset), 1), np.float32)\n",
    "\n",
    "for i, row in dataset.iterrows():\n",
    "    label[i] = row[TARGET_FEATURE]\n",
    "    data[i]  = np.fromiter([row[feature] for feature in CHOSEN_FEATURES], np.float32)\n",
    "    \n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "\n",
    "def list_classifier(neuron, activation, input_shape=()):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron, input_shape=input_shape, activation=activation))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", \n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(30, 8, 32, 'tanh')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train & test\n",
    "import itertools\n",
    "\n",
    "loo = KFold(8)\n",
    "\n",
    "epochs = [30]\n",
    "batch_size = [8]\n",
    "neurons = [32]\n",
    "activation = ['tanh']\n",
    "\n",
    "hyperparams = list(itertools.product(epochs, batch_size, neurons, activation))\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00016: early stopping\n",
      "[0.008007324555312558, 0.9964028776978417]\n",
      "Epoch 00018: early stopping\n",
      "[0.012075067698794732, 0.9892086330935251]\n",
      "Epoch 00013: early stopping\n",
      "[0.010577169039266572, 0.9928057541092523]\n",
      "Epoch 00013: early stopping\n",
      "[0.006531273885864577, 1.0]\n",
      "Epoch 00018: early stopping\n",
      "[0.16353614278648734, 0.8194945861286205]\n",
      "Epoch 00011: early stopping\n",
      "[0.14159637625036686, 0.8519855606426832]\n",
      "Epoch 00022: early stopping\n",
      "[0.11454717214521867, 0.8808664259927798]\n",
      "Epoch 00017: early stopping\n",
      "[0.13945136388716714, 0.848375452339434]\n",
      "(30, 8, 32, tanh)  - loss: 0.07454023628105981, acc: 0.9223924112505171 (std: 0.07898547607410975)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "early_stop_val_acc = EarlyStopping(monitor = \"val_loss\", min_delta=0.0005, patience=5, verbose=True)\n",
    "\n",
    "for epoch, batch, neuron, activation in hyperparams:\n",
    "\n",
    "    res = []\n",
    "    for (i, (train_index, test_index)) in enumerate(loo.split(data)):\n",
    "        \n",
    "        model = list_classifier(neuron, activation, input_shape=(len(CHOSEN_FEATURES),))\n",
    "        \n",
    "        data_train,   data_test =  data[train_index],  data[test_index]\n",
    "        label_train, label_test = label[train_index], label[test_index]\n",
    "        \n",
    "        \n",
    "        t = model.fit(data_train, label_train, epochs=epoch, batch_size=batch, shuffle=True, verbose=False,\n",
    "                 validation_split=0.3, callbacks=[early_stop_val_acc])\n",
    "        \n",
    "        r = model.evaluate(data_test, label_test, verbose=False)\n",
    "        print(r)\n",
    "        res.append(r)\n",
    "        \n",
    "    loss = statistics.mean(list(map(lambda x: x[0], res)))\n",
    "    acc  = statistics.mean(list(map(lambda x: x[1], res)))\n",
    "    acc_std = statistics.stdev(list(map(lambda x: x[1], res)))\n",
    "    \n",
    "    print(\"({}, {}, {}, {})  - loss: {}, acc: {} (std: {})\".format(epoch, batch, neuron, activation,\n",
    "                                                                   loss, acc, acc_std))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set the best hyperparameters from the results above\n",
    "best_epochs = 30    \n",
    "best_batch_size = 8\n",
    "best_neurons = 32\n",
    "best_activation = 'tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2220/2220 [==============================] - 1s 643us/step - loss: 0.2835 - acc: 0.5730\n",
      "Epoch 2/30\n",
      "2220/2220 [==============================] - 0s 77us/step - loss: 0.1106 - acc: 0.8896\n",
      "Epoch 3/30\n",
      "2220/2220 [==============================] - 0s 71us/step - loss: 0.0828 - acc: 0.9117\n",
      "Epoch 4/30\n",
      "2220/2220 [==============================] - 0s 72us/step - loss: 0.0744 - acc: 0.9203\n",
      "Epoch 5/30\n",
      "2220/2220 [==============================] - 0s 68us/step - loss: 0.0706 - acc: 0.9252\n",
      "Epoch 6/30\n",
      "2220/2220 [==============================] - 0s 70us/step - loss: 0.0683 - acc: 0.9266\n",
      "Epoch 7/30\n",
      "2220/2220 [==============================] - 0s 77us/step - loss: 0.0668 - acc: 0.9266\n",
      "Epoch 8/30\n",
      "2220/2220 [==============================] - 0s 70us/step - loss: 0.0658 - acc: 0.9288\n",
      "Epoch 9/30\n",
      "2220/2220 [==============================] - 0s 79us/step - loss: 0.0651 - acc: 0.9284\n",
      "Epoch 10/30\n",
      "2220/2220 [==============================] - 0s 88us/step - loss: 0.0644 - acc: 0.9306\n",
      "Epoch 11/30\n",
      "2220/2220 [==============================] - 0s 84us/step - loss: 0.0641 - acc: 0.9315\n",
      "Epoch 12/30\n",
      "2220/2220 [==============================] - 0s 70us/step - loss: 0.0636 - acc: 0.9311\n",
      "Epoch 13/30\n",
      "2220/2220 [==============================] - 0s 62us/step - loss: 0.0635 - acc: 0.9315\n",
      "Epoch 14/30\n",
      "2220/2220 [==============================] - 0s 72us/step - loss: 0.0632 - acc: 0.9302\n",
      "Epoch 15/30\n",
      "2220/2220 [==============================] - 0s 74us/step - loss: 0.0628 - acc: 0.9311\n",
      "Epoch 16/30\n",
      "2220/2220 [==============================] - 0s 68us/step - loss: 0.0626 - acc: 0.9315\n",
      "Epoch 17/30\n",
      "2220/2220 [==============================] - 0s 60us/step - loss: 0.0626 - acc: 0.9324\n",
      "Epoch 18/30\n",
      "2220/2220 [==============================] - 0s 76us/step - loss: 0.0623 - acc: 0.9320\n",
      "Epoch 19/30\n",
      "2220/2220 [==============================] - 0s 63us/step - loss: 0.0622 - acc: 0.9324\n",
      "Epoch 20/30\n",
      "2220/2220 [==============================] - 0s 64us/step - loss: 0.0620 - acc: 0.9329\n",
      "Epoch 21/30\n",
      "2220/2220 [==============================] - 0s 87us/step - loss: 0.0618 - acc: 0.9324\n",
      "Epoch 22/30\n",
      "2220/2220 [==============================] - 0s 81us/step - loss: 0.0616 - acc: 0.9324\n",
      "Epoch 23/30\n",
      "2220/2220 [==============================] - 0s 91us/step - loss: 0.0617 - acc: 0.9315\n",
      "Epoch 24/30\n",
      "2220/2220 [==============================] - 0s 72us/step - loss: 0.0614 - acc: 0.9320\n",
      "Epoch 25/30\n",
      "2220/2220 [==============================] - 0s 69us/step - loss: 0.0614 - acc: 0.9315\n",
      "Epoch 26/30\n",
      "2220/2220 [==============================] - 0s 83us/step - loss: 0.0609 - acc: 0.9324\n",
      "Epoch 27/30\n",
      "2220/2220 [==============================] - 0s 86us/step - loss: 0.0608 - acc: 0.9315\n",
      "Epoch 28/30\n",
      "2220/2220 [==============================] - 0s 108us/step - loss: 0.0605 - acc: 0.9320\n",
      "Epoch 29/30\n",
      "2220/2220 [==============================] - 0s 93us/step - loss: 0.0604 - acc: 0.9320\n",
      "Epoch 30/30\n",
      "2220/2220 [==============================] - 0s 113us/step - loss: 0.0603 - acc: 0.9324\n"
     ]
    }
   ],
   "source": [
    "## retrain the model on the whole dataset and save it\n",
    "model = list_classifier(best_neurons, best_activation, input_shape=(len(CHOSEN_FEATURES),))\n",
    "\n",
    "model.fit(data, label, epochs=best_epochs, \n",
    "                       batch_size=best_epochs, \n",
    "                       shuffle=True, verbose=True)\n",
    "\n",
    "model.save(\"models/list_classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
