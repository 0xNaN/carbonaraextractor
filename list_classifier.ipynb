{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas\n",
    "import numpy as np\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevant</th>\n",
       "      <th>avg_tag_in_li</th>\n",
       "      <th>depth</th>\n",
       "      <th>number_bold</th>\n",
       "      <th>number_br</th>\n",
       "      <th>number_div</th>\n",
       "      <th>number_img</th>\n",
       "      <th>number_links</th>\n",
       "      <th>number_p</th>\n",
       "      <th>number_relevants</th>\n",
       "      <th>number_row</th>\n",
       "      <th>relevants_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.38</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   relevant  avg_tag_in_li  depth  number_bold  number_br  number_div  \\\n",
       "0         1           0.00      2            2         26           0   \n",
       "1         1           0.00      1            0          0           0   \n",
       "2         1           1.00      2            0          0           0   \n",
       "3         1           1.38      5            0          0           4   \n",
       "4         1           2.50      5            0          0           4   \n",
       "\n",
       "   number_img  number_links  number_p  number_relevants  number_row  \\\n",
       "0           0             0         0                28           1   \n",
       "1           0             0         0                20           5   \n",
       "2           0             0         0                29           6   \n",
       "3           0             1         0                35           8   \n",
       "4           0             1         0                19           2   \n",
       "\n",
       "   relevants_ratio  \n",
       "0             0.12  \n",
       "1             0.51  \n",
       "2             0.52  \n",
       "3             0.48  \n",
       "4             0.59  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pandas.read_csv(\"data/list.csv\", sep=\"\\t\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['avg_tag_in_li', 'number_bold', 'number_img', 'number_links', 'number_relevants', 'relevants_ratio']\n",
      "[ 0.    2.    0.    0.   28.    0.12]\n"
     ]
    }
   ],
   "source": [
    "# Dataset to numpy arrays\n",
    "\n",
    "# choose the target feature and the features to train on\n",
    "TARGET_FEATURE = 'relevant'\n",
    "CHOSEN_FEATURES = ['avg_tag_in_li', 'number_img', 'number_relevants', 'number_links', 'number_bold', 'relevants_ratio']\n",
    "#CHOSEN_FEATURES = [\"relevants_ratio\"]\n",
    "\n",
    "CHOSEN_FEATURES = sorted(CHOSEN_FEATURES) # XXX as convention we sort the features based on their names\n",
    "print(CHOSEN_FEATURES)\n",
    "\n",
    "if (TARGET_FEATURE in CHOSEN_FEATURES): CHOSEN_FEATURES.remove(TARGET_FEATURE) # ensure we do not use target feature\n",
    "\n",
    "data  = np.ndarray((len(dataset), len(CHOSEN_FEATURES)), np.float32)\n",
    "label = np.ndarray((len(dataset), 2), np.float32)\n",
    "\n",
    "for i, row in dataset.iterrows():\n",
    "    label[i] = np.zeros(2)\n",
    "    label[i][int(row[TARGET_FEATURE])] = 1\n",
    "    \n",
    "    data[i]  = np.fromiter([row[feature] for feature in CHOSEN_FEATURES], np.float32)\n",
    "    \n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "\n",
    "def list_classifier(neuron, activation, input_shape=()):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron, input_shape=input_shape, activation=activation))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", \n",
    "          loss='binary_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(30, 8, 32, 'tanh'),\n",
       " (30, 8, 32, 'relu'),\n",
       " (30, 8, 32, 'relu'),\n",
       " (30, 8, 64, 'tanh'),\n",
       " (30, 8, 64, 'relu'),\n",
       " (30, 8, 64, 'relu')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train & test\n",
    "import itertools\n",
    "\n",
    "loo = KFold(6)\n",
    "\n",
    "epochs = [30]\n",
    "batch_size = [8]\n",
    "neurons = [32, 64]\n",
    "activation = ['tanh', 'relu', 'relu']\n",
    "\n",
    "hyperparams = list(itertools.product(epochs, batch_size, neurons, activation))\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00011: early stopping\n",
      "[0.09629759293150257, 0.9972972972972973]\n",
      "Epoch 00010: early stopping\n",
      "[0.11829464765819343, 0.9891891891891892]\n",
      "Epoch 00011: early stopping\n",
      "[0.10874255283458813, 0.9972972972972973]\n",
      "Epoch 00013: early stopping\n",
      "[0.5563361320946668, 0.8378378365490887]\n",
      "Epoch 00012: early stopping\n",
      "[0.6654756262495711, 0.8243243256130734]\n",
      "Epoch 00012: early stopping\n",
      "[0.5415318782265122, 0.8486486476820868]\n",
      "(30, 8, 32, tanh)  - loss: 0.3477797383325057, acc: 0.9157657656046722 (std: 0.08674651237257427)\n",
      "\n",
      "Epoch 00009: early stopping\n",
      "[0.16091313366148924, 0.9945945945945946]\n",
      "Epoch 00007: early stopping\n",
      "[0.14000922344826364, 0.9891891879004401]\n",
      "Epoch 00011: early stopping\n",
      "[0.22237959061120008, 0.9918918918918919]\n",
      "Epoch 00016: early stopping\n",
      "[0.6651997522727863, 0.835135133846386]\n",
      "Epoch 00009: early stopping\n",
      "[0.6553851945980175, 0.818918920207668]\n",
      "Epoch 00008: early stopping\n",
      "[0.6560526139027364, 0.8243243236799498]\n",
      "(30, 8, 32, relu)  - loss: 0.4166565847490822, acc: 0.9090090086868218 (std: 0.09095976614209743)\n",
      "\n",
      "Epoch 00007: early stopping\n",
      "[0.15964362669635462, 0.9945945945945946]\n",
      "Epoch 00009: early stopping\n",
      "[0.14091633308578183, 0.9837837824950347]\n",
      "Epoch 00010: early stopping\n",
      "[0.16805169771651965, 0.9945945945945946]\n",
      "Epoch 00010: early stopping\n",
      "[0.5126399777225545, 0.8405405392517915]\n",
      "Epoch 00013: early stopping\n",
      "[0.6433460312920648, 0.8270270283157761]\n",
      "Epoch 00013: early stopping\n",
      "[0.5739139002722663, 0.8486486476820868]\n",
      "(30, 8, 32, relu)  - loss: 0.36641859446425695, acc: 0.9148648644889797 (std: 0.08377070506844868)\n",
      "\n",
      "Epoch 00009: early stopping\n",
      "[0.10663136304230303, 0.9972972972972973]\n",
      "Epoch 00015: early stopping\n",
      "[0.11615385703138403, 0.9918918918918919]\n",
      "Epoch 00011: early stopping\n",
      "[0.08273257146010528, 0.9972972972972973]\n",
      "Epoch 00010: early stopping\n",
      "[0.6334303812400714, 0.8324324311436834]\n",
      "Epoch 00011: early stopping\n",
      "[0.6178068521860484, 0.8432432445319923]\n",
      "Epoch 00022: early stopping\n",
      "[0.5055806043985728, 0.8648648638983031]\n",
      "(30, 8, 64, tanh)  - loss: 0.3437226048930808, acc: 0.9211711710100775 (std: 0.08210909872584628)\n",
      "\n",
      "Epoch 00012: early stopping\n",
      "[0.12153019639285835, 0.9972972972972973]\n",
      "Epoch 00010: early stopping\n",
      "[0.07113778117943455, 0.9864864864864865]\n",
      "Epoch 00006: early stopping\n",
      "[0.40533739892212123, 0.9081081081081082]\n",
      "Epoch 00014: early stopping\n",
      "[0.6774580626874357, 0.8297297284409807]\n",
      "Epoch 00009: early stopping\n",
      "[0.6830127432539657, 0.8243243256130734]\n",
      "Epoch 00007: early stopping\n",
      "[0.5242256815369065, 0.856756755790195]\n",
      "(30, 8, 64, relu)  - loss: 0.41378364399545364, acc: 0.9004504502893569 (std: 0.07687118747506486)\n",
      "\n",
      "Epoch 00013: early stopping\n",
      "[0.12782042799769222, 0.9972972972972973]\n",
      "Epoch 00006: early stopping\n",
      "[0.1027494728363849, 0.9864864864864865]\n",
      "Epoch 00006: early stopping\n",
      "[0.20875435793721997, 0.9945945945945946]\n",
      "Epoch 00012: early stopping\n",
      "[0.6984509199052243, 0.8243243230355752]\n",
      "Epoch 00008: early stopping\n",
      "[0.8932115193959829, 0.8027027039914518]\n",
      "Epoch 00012: early stopping\n",
      "[0.6301187718236768, 0.8405405395739788]\n",
      "(30, 8, 64, relu)  - loss: 0.44351757831603017, acc: 0.907657657496564 (std: 0.09409779460900886)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "early_stop_val_acc = EarlyStopping(monitor = \"val_loss\", min_delta=0.005, patience=5, verbose=True)\n",
    "\n",
    "for epoch, batch, neuron, activation in hyperparams:\n",
    "\n",
    "    res = []\n",
    "    for (i, (train_index, test_index)) in enumerate(loo.split(data)):\n",
    "        \n",
    "        model = list_classifier(neuron, activation, input_shape=(len(CHOSEN_FEATURES),))\n",
    "        \n",
    "        data_train,   data_test =  data[train_index],  data[test_index]\n",
    "        label_train, label_test = label[train_index], label[test_index]\n",
    "        \n",
    "        \n",
    "        t = model.fit(data_train, label_train, epochs=epoch, batch_size=batch, shuffle=True, verbose=False,\n",
    "                 validation_split=0.3, callbacks=[early_stop_val_acc])\n",
    "        \n",
    "        r = model.evaluate(data_test, label_test, verbose=False)\n",
    "        print(r)\n",
    "        res.append(r)\n",
    "        \n",
    "    loss = statistics.mean(list(map(lambda x: x[0], res)))\n",
    "    acc  = statistics.mean(list(map(lambda x: x[1], res)))\n",
    "    acc_std = statistics.stdev(list(map(lambda x: x[1], res)))\n",
    "    \n",
    "    print(\"({}, {}, {}, {})  - loss: {}, acc: {} (std: {})\".format(epoch, batch, neuron, activation,\n",
    "                                                                   loss, acc, acc_std))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set the best hyperparameters from the results above\n",
    "best_epochs = 30    \n",
    "best_batch_size = 8\n",
    "best_neurons = 32\n",
    "best_activation = 'tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2220/2220 [==============================] - 2s 857us/step - loss: 0.5260 - acc: 0.7838\n",
      "Epoch 2/30\n",
      "2220/2220 [==============================] - 0s 67us/step - loss: 0.3085 - acc: 0.8892\n",
      "Epoch 3/30\n",
      "2220/2220 [==============================] - 0s 69us/step - loss: 0.2639 - acc: 0.8991\n",
      "Epoch 4/30\n",
      "2220/2220 [==============================] - 0s 71us/step - loss: 0.2513 - acc: 0.9068\n",
      "Epoch 5/30\n",
      "2220/2220 [==============================] - 0s 66us/step - loss: 0.2439 - acc: 0.9207\n",
      "Epoch 6/30\n",
      "2220/2220 [==============================] - 0s 67us/step - loss: 0.2392 - acc: 0.9243\n",
      "Epoch 7/30\n",
      "2220/2220 [==============================] - 0s 68us/step - loss: 0.2332 - acc: 0.9270\n",
      "Epoch 8/30\n",
      "2220/2220 [==============================] - 0s 72us/step - loss: 0.2309 - acc: 0.9284\n",
      "Epoch 9/30\n",
      "2220/2220 [==============================] - 0s 67us/step - loss: 0.2286 - acc: 0.9297\n",
      "Epoch 10/30\n",
      "2220/2220 [==============================] - 0s 67us/step - loss: 0.2281 - acc: 0.9293\n",
      "Epoch 11/30\n",
      "2220/2220 [==============================] - 0s 71us/step - loss: 0.2248 - acc: 0.9284\n",
      "Epoch 12/30\n",
      "2220/2220 [==============================] - 0s 67us/step - loss: 0.2243 - acc: 0.9279\n",
      "Epoch 13/30\n",
      "2220/2220 [==============================] - 0s 71us/step - loss: 0.2239 - acc: 0.9288\n",
      "Epoch 14/30\n",
      "2220/2220 [==============================] - 0s 68us/step - loss: 0.2229 - acc: 0.9302\n",
      "Epoch 15/30\n",
      "2220/2220 [==============================] - 0s 68us/step - loss: 0.2235 - acc: 0.9288\n",
      "Epoch 16/30\n",
      "2220/2220 [==============================] - 0s 67us/step - loss: 0.2218 - acc: 0.9297\n",
      "Epoch 17/30\n",
      "2220/2220 [==============================] - 0s 68us/step - loss: 0.2215 - acc: 0.9288\n",
      "Epoch 18/30\n",
      "2220/2220 [==============================] - 0s 68us/step - loss: 0.2196 - acc: 0.9288\n",
      "Epoch 19/30\n",
      "2220/2220 [==============================] - 0s 78us/step - loss: 0.2208 - acc: 0.9284\n",
      "Epoch 20/30\n",
      "2220/2220 [==============================] - 0s 67us/step - loss: 0.2184 - acc: 0.9293\n",
      "Epoch 21/30\n",
      "2220/2220 [==============================] - 0s 84us/step - loss: 0.2157 - acc: 0.9297\n",
      "Epoch 22/30\n",
      "2220/2220 [==============================] - 0s 77us/step - loss: 0.2148 - acc: 0.9302\n",
      "Epoch 23/30\n",
      "2220/2220 [==============================] - 0s 71us/step - loss: 0.2129 - acc: 0.9306\n",
      "Epoch 24/30\n",
      "2220/2220 [==============================] - 0s 71us/step - loss: 0.2118 - acc: 0.9311\n",
      "Epoch 25/30\n",
      "2220/2220 [==============================] - 0s 93us/step - loss: 0.2096 - acc: 0.9306\n",
      "Epoch 26/30\n",
      "2220/2220 [==============================] - 0s 105us/step - loss: 0.2074 - acc: 0.9311\n",
      "Epoch 27/30\n",
      "2220/2220 [==============================] - 0s 98us/step - loss: 0.2054 - acc: 0.9315\n",
      "Epoch 28/30\n",
      "2220/2220 [==============================] - 0s 103us/step - loss: 0.2041 - acc: 0.9306\n",
      "Epoch 29/30\n",
      "2220/2220 [==============================] - 0s 102us/step - loss: 0.2025 - acc: 0.9311\n",
      "Epoch 30/30\n",
      "2220/2220 [==============================] - 0s 95us/step - loss: 0.1991 - acc: 0.9311\n"
     ]
    }
   ],
   "source": [
    "## retrain the model on the whole dataset and save it\n",
    "model = list_classifier(best_neurons, best_activation, input_shape=(len(CHOSEN_FEATURES),))\n",
    "\n",
    "model.fit(data, label, epochs=best_epochs, \n",
    "                       batch_size=best_epochs, \n",
    "                       shuffle=True, verbose=True)\n",
    "\n",
    "model.save(\"models/list_classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
